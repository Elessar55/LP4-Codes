{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_GcJlVrDgBk"
   },
   "source": [
    "Name: **Ruturaj Kiran Patil**<br>\n",
    "Div: **BE09-S09**<br>\n",
    "Roll no: **43165**<br>\n",
    "Title: **Assignment 5: Implement the Continuous Bag of Words (CBOW) Model**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V51q50EbF-T9"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from keras.preprocessing import text\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBUwYdBJElVz"
   },
   "outputs": [],
   "source": [
    "#taking random sentences as data\n",
    "data = \"\"\"Deep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised. \n",
    "Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and Transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
    "\"\"\"\n",
    "dl_data = data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "celNk9LmEvm8",
    "outputId": "2a981903-d1ee-4bb0-c294-23529335b9f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 75\n",
      "Vocabulary Sample: [('learning', 1), ('deep', 2), ('networks', 3), ('neural', 4), ('and', 5), ('as', 6), ('of', 7), ('machine', 8), ('supervised', 9), ('have', 10)]\n"
     ]
    }
   ],
   "source": [
    "#tokenization\n",
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(dl_data)\n",
    "word2id = tokenizer.word_index\n",
    "\n",
    "word2id['PAD'] = 0\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in dl_data]\n",
    "\n",
    "vocab_size = len(word2id)\n",
    "embed_size = 100\n",
    "window_size = 2 \n",
    "\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Vocabulary Sample:', list(word2id.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAxNYDanInQC"
   },
   "outputs": [],
   "source": [
    "#generating (context word, target/label word) pairs\n",
    "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
    "    context_length = window_size*2\n",
    "    for words in corpus:\n",
    "        sentence_length = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            context_words = []\n",
    "            label_word   = []            \n",
    "            start = index - window_size\n",
    "            end = index + window_size + 1\n",
    "            \n",
    "            context_words.append([words[i] \n",
    "                                 for i in range(start, end) \n",
    "                                 if 0 <= i < sentence_length \n",
    "                                 and i != index])\n",
    "            label_word.append(word)\n",
    "\n",
    "            x = pad_sequences(context_words, maxlen=context_length)\n",
    "            y = np_utils.to_categorical(label_word, vocab_size)\n",
    "            yield (x, y)\n",
    "            \n",
    "i = 0\n",
    "for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
    "    if 0 not in x[0]:\n",
    "        # print('Context (X):', [id2word[w] for w in x[0]], '-> Target (Y):', id2word[np.argwhere(y[0])[0][0]])\n",
    "    \n",
    "        if i == 10:\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rb5dNmoZKZBv",
    "outputId": "1eb3ff91-e682-4061-b920-6fdec4aea5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4, 100)            7500      \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 75)                7575      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,075\n",
      "Trainable params: 15,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model building\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda\n",
    "\n",
    "cbow = Sequential()\n",
    "cbow.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=window_size*2))\n",
    "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)))\n",
    "cbow.add(Dense(vocab_size, activation='softmax'))\n",
    "cbow.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "print(cbow.summary())\n",
    "\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(cbow, show_shapes=True, show_layer_names=False, rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xs12C3MDK1q4",
    "outputId": "7a3c7f24-17fb-492c-89e6-d4cfcf6a0b01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tLoss: 434.16670751571655\n",
      "\n",
      "Epoch: 2 \tLoss: 428.92622661590576\n",
      "\n",
      "Epoch: 3 \tLoss: 425.2899193763733\n",
      "\n",
      "Epoch: 4 \tLoss: 421.9985513687134\n",
      "\n",
      "Epoch: 5 \tLoss: 419.6197762489319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    loss = 0.\n",
    "    i = 0\n",
    "    for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
    "        i += 1\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "        if i % 100000 == 0:\n",
    "            print('Processed {} (context, word) pairs'.format(i))\n",
    "\n",
    "    print('Epoch:', epoch, '\\tLoss:', loss)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "TZ3_QGKVK6Tj",
    "outputId": "861c056c-8964-421f-9203-bf8e7e22d656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f6d623fc-055b-4ca6-82ca-0fc03862cf60\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deep</th>\n",
       "      <td>-0.061168</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>-0.058615</td>\n",
       "      <td>0.015615</td>\n",
       "      <td>-0.037778</td>\n",
       "      <td>0.053087</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>-0.042982</td>\n",
       "      <td>-0.026489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>-0.019780</td>\n",
       "      <td>-0.056551</td>\n",
       "      <td>-0.023060</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>-0.014822</td>\n",
       "      <td>0.022432</td>\n",
       "      <td>0.032463</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>-0.039815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>networks</th>\n",
       "      <td>-0.018597</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>0.051940</td>\n",
       "      <td>0.017501</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.010865</td>\n",
       "      <td>-0.003026</td>\n",
       "      <td>-0.035222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015500</td>\n",
       "      <td>0.011446</td>\n",
       "      <td>0.019511</td>\n",
       "      <td>0.044267</td>\n",
       "      <td>-0.046587</td>\n",
       "      <td>-0.049015</td>\n",
       "      <td>-0.004496</td>\n",
       "      <td>-0.001273</td>\n",
       "      <td>-0.012510</td>\n",
       "      <td>0.018941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural</th>\n",
       "      <td>0.031219</td>\n",
       "      <td>-0.036100</td>\n",
       "      <td>0.019787</td>\n",
       "      <td>-0.006211</td>\n",
       "      <td>-0.008252</td>\n",
       "      <td>-0.020533</td>\n",
       "      <td>0.039017</td>\n",
       "      <td>0.041702</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>-0.032711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029301</td>\n",
       "      <td>-0.011865</td>\n",
       "      <td>-0.012609</td>\n",
       "      <td>-0.003538</td>\n",
       "      <td>0.021192</td>\n",
       "      <td>-0.019977</td>\n",
       "      <td>-0.047386</td>\n",
       "      <td>-0.018158</td>\n",
       "      <td>-0.028764</td>\n",
       "      <td>0.025445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>-0.014529</td>\n",
       "      <td>-0.031334</td>\n",
       "      <td>-0.016509</td>\n",
       "      <td>0.042348</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.016299</td>\n",
       "      <td>0.019438</td>\n",
       "      <td>0.037361</td>\n",
       "      <td>-0.045116</td>\n",
       "      <td>-0.027266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026395</td>\n",
       "      <td>0.041459</td>\n",
       "      <td>0.030011</td>\n",
       "      <td>-0.008583</td>\n",
       "      <td>-0.011443</td>\n",
       "      <td>-0.045769</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>0.011912</td>\n",
       "      <td>0.031680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.024306</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>-0.017554</td>\n",
       "      <td>-0.003187</td>\n",
       "      <td>-0.019816</td>\n",
       "      <td>-0.036603</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>-0.034629</td>\n",
       "      <td>0.021741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033953</td>\n",
       "      <td>-0.041413</td>\n",
       "      <td>0.008849</td>\n",
       "      <td>-0.048005</td>\n",
       "      <td>-0.046271</td>\n",
       "      <td>0.023641</td>\n",
       "      <td>0.028201</td>\n",
       "      <td>-0.032720</td>\n",
       "      <td>-0.041773</td>\n",
       "      <td>-0.020650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6d623fc-055b-4ca6-82ca-0fc03862cf60')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f6d623fc-055b-4ca6-82ca-0fc03862cf60 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f6d623fc-055b-4ca6-82ca-0fc03862cf60');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                0         1         2         3         4         5   \\\n",
       "deep     -0.061168  0.017272  0.022730 -0.058615  0.015615 -0.037778   \n",
       "networks -0.018597  0.005401  0.001760 -0.030000  0.051940  0.017501   \n",
       "neural    0.031219 -0.036100  0.019787 -0.006211 -0.008252 -0.020533   \n",
       "and      -0.014529 -0.031334 -0.016509  0.042348  0.006202  0.016299   \n",
       "as        0.003475  0.024306  0.012624 -0.017554 -0.003187 -0.019816   \n",
       "\n",
       "                6         7         8         9   ...        90        91  \\\n",
       "deep      0.053087  0.003329 -0.042982 -0.026489  ...  0.015849 -0.019780   \n",
       "networks  0.000603  0.010865 -0.003026 -0.035222  ... -0.015500  0.011446   \n",
       "neural    0.039017  0.041702  0.005039 -0.032711  ...  0.029301 -0.011865   \n",
       "and       0.019438  0.037361 -0.045116 -0.027266  ...  0.026395  0.041459   \n",
       "as       -0.036603  0.005854 -0.034629  0.021741  ... -0.033953 -0.041413   \n",
       "\n",
       "                92        93        94        95        96        97  \\\n",
       "deep     -0.056551 -0.023060  0.003928 -0.014822  0.022432  0.032463   \n",
       "networks  0.019511  0.044267 -0.046587 -0.049015 -0.004496 -0.001273   \n",
       "neural   -0.012609 -0.003538  0.021192 -0.019977 -0.047386 -0.018158   \n",
       "and       0.030011 -0.008583 -0.011443 -0.045769  0.034511  0.009879   \n",
       "as        0.008849 -0.048005 -0.046271  0.023641  0.028201 -0.032720   \n",
       "\n",
       "                98        99  \n",
       "deep      0.000389 -0.039815  \n",
       "networks -0.012510  0.018941  \n",
       "neural   -0.028764  0.025445  \n",
       "and       0.011912  0.031680  \n",
       "as       -0.041773 -0.020650  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = cbow.get_weights()[0]\n",
    "weights = weights[1:]\n",
    "print(weights.shape)\n",
    "\n",
    "pd.DataFrame(weights, index=list(id2word.values())[1:]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFs2IAn_LAYS",
    "outputId": "dc4e8c51-1b08-4930-c673-8083b4f4a4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74, 74)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'deep': ['learning', 'also', 'where', 'board', 'networks']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "distance_matrix = euclidean_distances(weights)\n",
    "print(distance_matrix.shape)\n",
    "\n",
    "similar_words = {search_term: [id2word[idx] for idx in distance_matrix[word2id[search_term]-1].argsort()[1:6]+1] \n",
    "                   for search_term in ['deep']}\n",
    "\n",
    "similar_words"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
